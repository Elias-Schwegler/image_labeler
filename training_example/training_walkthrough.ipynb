{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ“ Model Training Walkthrough\n",
                "\n",
                "This notebook demonstrates how to train a custom image classifier using the labeled dataset generated by the Image Labeler tool. \n",
                "\n",
                "We will fine-tune a pre-trained **ResNet18** model using PyTorch.\n",
                "\n",
                "### ðŸš€ Prerequisites\n",
                "Ensure you have run the Image Labeler and generated a dataset in `data/processed` (or a similar path) containing `train/` and `test/` folders."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup\n",
                "First, we install the necessary dependencies (`torch`, `torchvision`, etc.)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Imports\n",
                "Import necessary libraries for data manipulation, file handling, and PyTorch operations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import models, transforms\n",
                "from PIL import Image\n",
                "from tqdm import tqdm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configuration\n",
                "Set up your training parameters. Adjust `DATA_DIR` to point to your split dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Path to the directory containing 'train' and 'test' folders\n",
                "DATA_DIR = \"../data/processed\"\n",
                "\n",
                "# Hyperparameters\n",
                "BATCH_SIZE = 4\n",
                "NUM_EPOCHS = 5\n",
                "LEARNING_RATE = 0.001\n",
                "\n",
                "# Device configuration\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Custom Dataset Definition\n",
                "We define a custom `Dataset` class that reads the `labels.json` file created by our tool. It maps images to their labels dynamically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class LabelerDataset(Dataset):\n",
                "    def __init__(self, data_dir, transform=None):\n",
                "        self.data_dir = data_dir\n",
                "        self.transform = transform\n",
                "        self.params_file = os.path.join(data_dir, \"labels.json\")\n",
                "        \n",
                "        if not os.path.exists(self.params_file):\n",
                "            raise FileNotFoundError(f\"labels.json not found in {data_dir}\")\n",
                "\n",
                "        with open(self.params_file, \"r\") as f:\n",
                "            self.data = json.load(f)\n",
                "\n",
                "        # Filter out invalid images\n",
                "        self.valid_data = []\n",
                "        for item in self.data:\n",
                "            img_name = item.get(\"filename\")\n",
                "            # Check existence\n",
                "            if img_name and os.path.exists(os.path.join(data_dir, img_name)):\n",
                "                self.valid_data.append(item)\n",
                "        \n",
                "        self.labels = [item[\"label\"] for item in self.valid_data]\n",
                "\n",
                "    def set_class_map(self, class_to_idx):\n",
                "        self.class_to_idx = class_to_idx\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.valid_data)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        item = self.valid_data[idx]\n",
                "        img_path = os.path.join(self.data_dir, item[\"filename\"])\n",
                "        image = Image.open(img_path).convert(\"RGB\")\n",
                "        label = item[\"label\"]\n",
                "        \n",
                "        if self.transform:\n",
                "            image = self.transform(image)\n",
                "            \n",
                "        label_idx = self.class_to_idx[label]\n",
                "        return image, label_idx"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Data Preparation\n",
                "Define image transformations (resizing, normalization) and create DataLoaders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data Augmentation and Normalization\n",
                "data_transforms = {\n",
                "    'train': transforms.Compose([\n",
                "        transforms.RandomResizedCrop(224),\n",
                "        transforms.RandomHorizontalFlip(),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "    ]),\n",
                "    'test': transforms.Compose([\n",
                "        transforms.Resize(256),\n",
                "        transforms.CenterCrop(224),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "    ]),\n",
                "}\n",
                "\n",
                "# Initialize Datasets\n",
                "image_datasets = {}\n",
                "for phase in ['train', 'test']:\n",
                "    dir_path = os.path.join(DATA_DIR, phase)\n",
                "    if os.path.exists(dir_path):\n",
                "        image_datasets[phase] = LabelerDataset(dir_path, transform=data_transforms[phase])\n",
                "    else:\n",
                "        print(f\"Warning: {phase} directory not found at {dir_path}\")\n",
                "\n",
                "# Auto-detect classes from Training set\n",
                "if 'train' in image_datasets:\n",
                "    all_labels = sorted(list(set(image_datasets['train'].labels)))\n",
                "    class_to_idx = {label: idx for idx, label in enumerate(all_labels)}\n",
                "    print(f\"Found {len(all_labels)} classes: {all_labels}\")\n",
                "    \n",
                "    # Apply class map to all datasets\n",
                "    for phase in image_datasets:\n",
                "        image_datasets[phase].set_class_map(class_to_idx)\n",
                "else:\n",
                "    print(\"Error: No training data found. Cannot proceed.\")\n",
                "\n",
                "# Create DataLoaders\n",
                "dataloaders = {x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True) \n",
                "               for x in image_datasets}\n",
                "dataset_sizes = {x: len(image_datasets[x]) for x in image_datasets}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Model Setup\n",
                "We use **ResNet18**, a lightweight CNN. We replace the final fully connected layer (`fc`) to output the number of classes present in our dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Pretrained ResNet18\n",
                "try:\n",
                "    from torchvision.models import ResNet18_Weights\n",
                "    weights = ResNet18_Weights.IMAGENET1K_V1\n",
                "except ImportError:\n",
                "    weights = None # Fallback for older torch versions\n",
                "\n",
                "model = models.resnet18(weights=weights)\n",
                "\n",
                "# Modify the last layer\n",
                "num_ftrs = model.fc.in_features\n",
                "model.fc = nn.Linear(num_ftrs, len(all_labels))\n",
                "\n",
                "model = model.to(device)\n",
                "\n",
                "# Loss and Optimizer\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
                "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training Loop\n",
                "The training process involves iterating through epochs. In each epoch, we: \n",
                "1.  **Train**: Update model weights using backpropagation.\n",
                "2.  **Evaluate**: Check performance on the test set without updating weights."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
                "    best_acc = 0.0\n",
                "\n",
                "    for epoch in range(num_epochs):\n",
                "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
                "        print('-' * 10)\n",
                "\n",
                "        for phase in ['train', 'test']:\n",
                "            if phase not in dataloaders:\n",
                "                continue\n",
                "\n",
                "            if phase == 'train':\n",
                "                model.train()\n",
                "            else:\n",
                "                model.eval()\n",
                "\n",
                "            running_loss = 0.0\n",
                "            running_corrects = 0\n",
                "\n",
                "            # Batch iteration\n",
                "            for inputs, labels in tqdm(dataloaders[phase], desc=phase):\n",
                "                inputs = inputs.to(device)\n",
                "                labels = labels.to(device)\n",
                "\n",
                "                optimizer.zero_grad()\n",
                "\n",
                "                # Forward pass\n",
                "                with torch.set_grad_enabled(phase == 'train'):\n",
                "                    outputs = model(inputs)\n",
                "                    _, preds = torch.max(outputs, 1)\n",
                "                    loss = criterion(outputs, labels)\n",
                "\n",
                "                    # Backward pass only in training\n",
                "                    if phase == 'train':\n",
                "                        loss.backward()\n",
                "                        optimizer.step()\n",
                "\n",
                "                running_loss += loss.item() * inputs.size(0)\n",
                "                running_corrects += torch.sum(preds == labels.data)\n",
                "            \n",
                "            if phase == 'train':\n",
                "                scheduler.step()\n",
                "\n",
                "            epoch_loss = running_loss / dataset_sizes[phase]\n",
                "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
                "\n",
                "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
                "            \n",
                "    print('Training complete')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Execute Training\n",
                "Run the training loop."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'train' in dataloaders:\n",
                "    train_model(model, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Save and Inference\n",
                "Save the trained model and class map for future use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save Model\n",
                "save_path = os.path.join(DATA_DIR, \"model.pth\")\n",
                "torch.save(model.state_dict(), save_path)\n",
                "print(f\"Model saved to {save_path}\")\n",
                "\n",
                "# Save Class Map\n",
                "class_map_path = os.path.join(DATA_DIR, \"class_map.json\")\n",
                "with open(class_map_path, \"w\") as f:\n",
                "    json.dump(class_to_idx, f, indent=4)\n",
                "print(f\"Class map saved to {class_map_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "HSLU",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
